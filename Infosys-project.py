# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uz6ctqawdjZj2p8xzLDmKrOK1MUlFmF9
"""

!pip install moviepy

import os
from google.colab import files
from moviepy.editor import VideoFileClip

# Upload the video file
uploaded = files.upload()

# Get the filename of the uploaded video
for fn in uploaded.keys():
    print('User uploaded file "{name}" with length {length} bytes'.format(
        name=fn, length=len(uploaded[fn])))
    video_filename = fn

# Convert the video to audio
video = VideoFileClip(video_filename)
audio = video.audio
audio.write_audiofile(video_filename.split('.')[0] + '.mp3')

# Download the audio file
files.download(video_filename.split('.')[0] + '.mp3')

!pip install git+https://github.com/openai/whisper.git
!sudo apt update && sudo apt install ffmpeg

import os
import whisper
from google.colab import files
import torch
import time

def transcribe_audio():
    # Upload the audio file
    print("Please upload your audio file...")
    uploaded = files.upload()

    # Get the filename of the uploaded audio
    audio_file = list(uploaded.keys())[0]
    print(f"Processing file: {audio_file}")

    # Load the Whisper model
    print("Loading Whisper model...")
    # Choose model size: tiny, base, small, medium, large
    model = whisper.load_model("base")

    # Start timing
    start_time = time.time()

    # Transcribe the audio
    print("Transcribing audio... This may take a while depending on the file size.")
    result = model.transcribe(audio_file, language="english")

    # Calculate processing time
    processing_time = time.time() - start_time
    print(f"\nProcessing time: {processing_time:.2f} seconds")

    # Save transcription to file
    output_filename = f"transcription_{audio_file.split('.')[0]}.txt"
    with open(output_filename, "w", encoding="utf-8") as f:
        f.write(result["text"])

    # Display transcription
    print("\nTranscription:")
    print(result["text"])

    # Save segments with timestamps if available
    segments_filename = f"segments_{audio_file.split('.')[0]}.txt"
    with open(segments_filename, "w", encoding="utf-8") as f:
        for segment in result["segments"]:
            start_time = time.strftime('%H:%M:%S', time.gmtime(segment['start']))
            end_time = time.strftime('%H:%M:%S', time.gmtime(segment['end']))
            f.write(f"[{start_time} --> {end_time}] {segment['text']}\n")

    # Download the transcription files
    print("\nDownloading transcription files...")
    files.download(output_filename)
    files.download(segments_filename)

# Check if CUDA (GPU) is available
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU Model: {torch.cuda.get_device_name(0)}")

# Run the transcription
transcribe_audio()

!pip install transformers vaderSentiment textblob nltk plotly wordcloud scikit-learn

!python -m textblob.download_corpora

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from transformers import pipeline
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
import nltk
from nltk.tokenize import sent_tokenize
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import defaultdict
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from google.colab import files

# Download required NLTK data
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')

class SentimentAnalyzer:
    def __init__(self):
        # Initialize sentiment analyzers
        self.vader = SentimentIntensityAnalyzer()
        self.emotion_classifier = pipeline("text-classification",
                                        model="j-hartmann/emotion-english-distilroberta-base",
                                        return_all_scores=True)

        # Initialize RoBERTa model for aspect-based sentiment
        self.tokenizer = AutoTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
        self.model = AutoModelForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")

    def analyze_text(self, text):
        # Split text into sentences
        sentences = sent_tokenize(text)

        # Initialize results dictionary
        results = {
            'overall_sentiment': self.analyze_overall_sentiment(text),
            'emotional_analysis': self.analyze_emotions(text),
            'sentence_sentiments': self.analyze_sentences(sentences),
            'aspect_based': self.extract_aspects_and_sentiments(text),
            'text_stats': self.analyze_text_statistics(text)
        }
        return results

    def analyze_overall_sentiment(self, text):
        # VADER sentiment analysis
        vader_scores = self.vader.polarity_scores(text)

        # TextBlob sentiment analysis
        blob = TextBlob(text)
        textblob_sentiment = blob.sentiment

        return {
            'vader': vader_scores,
            'textblob': {
                'polarity': textblob_sentiment.polarity,
                'subjectivity': textblob_sentiment.subjectivity
            }
        }

    def analyze_emotions(self, text):
        emotions = self.emotion_classifier(text)
        return emotions[0]

    def analyze_sentences(self, sentences):
        sentence_analysis = []
        for sentence in sentences:
            vader_scores = self.vader.polarity_scores(sentence)
            emotion_scores = self.emotion_classifier(sentence)[0]

            sentence_analysis.append({
                'sentence': sentence,
                'vader_scores': vader_scores,
                'emotions': emotion_scores
            })
        return sentence_analysis

    def extract_aspects_and_sentiments(self, text):
        # Simple aspect extraction using NLTK
        blob = TextBlob(text)
        aspects = []

        for sentence in blob.sentences:
            for token in sentence.noun_phrases:
                aspects.append(token)

        # Analyze sentiment for each aspect
        aspect_sentiments = {}
        for aspect in set(aspects):
            # Find sentences containing the aspect
            relevant_sentences = [s for s in blob.sentences if aspect in s.string]
            if relevant_sentences:
                sentiment_scores = [s.sentiment.polarity for s in relevant_sentences]
                aspect_sentiments[aspect] = np.mean(sentiment_scores)

        return aspect_sentiments

    def analyze_text_statistics(self, text):
        blob = TextBlob(text)
        return {
            'word_count': len(text.split()),
            'sentence_count': len(blob.sentences),
            'average_sentence_length': len(text.split()) / len(blob.sentences),
            'unique_words': len(set(text.split()))
        }

    def generate_visualizations(self, results):
        # Create visualizations
        figs = {}

        # 1. Overall sentiment distribution
        vader_scores = results['overall_sentiment']['vader']
        fig_vader = go.Figure(data=[
            go.Bar(x=list(vader_scores.keys()),
                  y=list(vader_scores.values()),
                  marker_color=['lightblue', 'lightgreen', 'pink', 'purple'])
        ])
        fig_vader.update_layout(title='VADER Sentiment Scores')
        figs['vader_sentiment'] = fig_vader

        # 2. Emotion distribution
        emotions = results['emotional_analysis']
        fig_emotions = px.bar(
            x=[e['label'] for e in emotions],
            y=[e['score'] for e in emotions],
            title='Emotion Distribution'
        )
        figs['emotions'] = fig_emotions

        # 3. Aspect-based sentiment
        aspect_sentiments = results['aspect_based']
        if aspect_sentiments:
            fig_aspects = px.bar(
                x=list(aspect_sentiments.keys()),
                y=list(aspect_sentiments.values()),
                title='Aspect-based Sentiment Analysis'
            )
            figs['aspects'] = fig_aspects

        return figs

def main():
    # Upload transcription file
    print("Please upload your transcription file...")
    uploaded = files.upload()

    # Read the transcription
    filename = list(uploaded.keys())[0]
    with open(filename, 'r', encoding='utf-8') as file:
        text = file.read()

    # Initialize analyzer
    analyzer = SentimentAnalyzer()

    # Perform analysis
    print("Analyzing sentiment...")
    results = analyzer.analyze_text(text)

    # Generate visualizations
    print("Generating visualizations...")
    figs = analyzer.generate_visualizations(results)

    # Create detailed report
    report = f"""
    Sentiment Analysis Report
    ========================

    1. Overall Sentiment
    -------------------
    VADER Sentiment:
    - Positive: {results['overall_sentiment']['vader']['pos']:.3f}
    - Neutral: {results['overall_sentiment']['vader']['neu']:.3f}
    - Negative: {results['overall_sentiment']['vader']['neg']:.3f}
    - Compound: {results['overall_sentiment']['vader']['compound']:.3f}

    TextBlob Sentiment:
    - Polarity: {results['overall_sentiment']['textblob']['polarity']:.3f}
    - Subjectivity: {results['overall_sentiment']['textblob']['subjectivity']:.3f}

    2. Dominant Emotions
    -------------------
    {sorted(results['emotional_analysis'], key=lambda x: x['score'], reverse=True)}

    3. Text Statistics
    -----------------
    - Word Count: {results['text_stats']['word_count']}
    - Sentence Count: {results['text_stats']['sentence_count']}
    - Average Sentence Length: {results['text_stats']['average_sentence_length']:.1f}
    - Unique Words: {results['text_stats']['unique_words']}

    4. Key Aspects and their Sentiments
    ---------------------------------
    """

    for aspect, sentiment in results['aspect_based'].items():
        report += f"- {aspect}: {sentiment:.3f}\n"

    # Save report
    report_filename = f"sentiment_analysis_report_{filename.split('.')[0]}.txt"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(report)

    # Display visualizations
    for fig_name, fig in figs.items():
        fig.show()

    # Download report
    files.download(report_filename)

    print("\nAnalysis complete! Report has been downloaded.")

if __name__ == "__main__":
    main()

!pip install pyannote.audio
!pip install torch
!pip install pydub

import torch
from pyannote.audio import Pipeline
from google.colab import files
import json
from pydub import AudioSegment
import os
import pandas as pd
import matplotlib.pyplot as plt

# First, let's verify the installation and CUDA availability
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")

def process_diarization(access_token, audio_path):
    """
    Process audio file for speaker diarization
    """
    try:
        # Initialize pipeline
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization",
            use_auth_token=access_token
        )

        # Use GPU if available
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        pipeline = pipeline.to(device)

        # Get diarization results
        diarization = pipeline(audio_path)

        # Convert results to structured format
        segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append({
                'speaker': speaker,
                'start': turn.start,
                'end': turn.end,
                'duration': turn.end - turn.start
            })

        return segments

    except Exception as e:
        print(f"Error during diarization: {str(e)}")
        return None

def create_visualizations(segments):
    """
    Create visualizations for the diarization results
    """
    if not segments:
        return

    df = pd.DataFrame(segments)

    # Speaker Timeline
    plt.figure(figsize=(15, 4))
    for speaker in df['speaker'].unique():
        speaker_segments = df[df['speaker'] == speaker]
        # Iterate through each segment for the speaker
        for index, row in speaker_segments.iterrows():
            plt.hlines(y=speaker, xmin=row['start'], xmax=row['end'],
                      label=speaker if index == speaker_segments.index[0] else "",  # Only label the first segment
                      linewidth=10)

    plt.ylabel('Speakers')
    plt.xlabel('Time (seconds)')
    plt.title('Speaker Timeline')
    plt.grid(True)
    plt.legend()
    plt.savefig('speaker_timeline.png')
    plt.close()

    # Speaking Time Distribution
    plt.figure(figsize=(10, 6))
    speaker_times = df.groupby('speaker')['duration'].sum()
    plt.pie(speaker_times, labels=speaker_times.index, autopct='%1.1f%%')
    plt.title('Speaking Time Distribution')
    plt.axis('equal')
    plt.savefig('speaking_time_distribution.png')
    plt.close()

    return df

def generate_report(df):
    """
    Generate analysis report
    """
    if df is None or df.empty:
        return None

    total_duration = df['duration'].sum()
    speaker_stats = df.groupby('speaker').agg({
        'duration': ['sum', 'count', 'mean']
    }).round(2)

    speaker_stats.columns = ['total_time', 'num_segments', 'avg_segment_length']
    speaker_stats['speaking_percentage'] = (speaker_stats['total_time'] / total_duration * 100).round(2)

    return {
        'total_duration': total_duration,
        'num_speakers': len(df['speaker'].unique()),
        'speaker_stats': speaker_stats
    }

def save_results(segments, base_filename):
    """
    Save results in multiple formats
    """
    if not segments:
        return

    # Save JSON
    with open(f"{base_filename}_diarization.json", 'w') as f:
        json.dump(segments, f, indent=4)

    # Save CSV
    df = pd.DataFrame(segments)
    df.to_csv(f"{base_filename}_diarization.csv", index=False)

    # Save VTT (for subtitles)
    with open(f"{base_filename}_diarization.vtt", 'w') as f:
        f.write("WEBVTT\n\n")
        for segment in segments:
            start_time = format_timestamp(segment['start'])
            end_time = format_timestamp(segment['end'])
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"[{segment['speaker']}]\n\n")

def format_timestamp(seconds):
    """Convert seconds to VTT timestamp format"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = seconds % 60
    return f"{hours:02d}:{minutes:02d}:{seconds:06.3f}"

def main():
    print("Please enter your HuggingFace access token:")
    access_token = input()

    print("\nPlease upload your audio file...")
    uploaded = files.upload()
    audio_path = list(uploaded.keys())[0]

    print("\nProcessing audio... This may take a while.")
    segments = process_diarization(access_token, audio_path)

    if segments:
        print("\nCreating visualizations and analysis...")
        df = create_visualizations(segments)
        report = generate_report(df)

        print("\nSaving results...")
        output_base = os.path.splitext(audio_path)[0]
        save_results(segments, output_base)

        # Print summary
        print("\nDiarization Summary:")
        print(f"Total Duration: {report['total_duration']:.2f} seconds")
        print(f"Number of Speakers: {report['num_speakers']}")
        print("\nSpeaker Statistics:")
        print(report['speaker_stats'])

        # Download results
        files.download(f"{output_base}_diarization.json")
        files.download(f"{output_base}_diarization.csv")
        files.download(f"{output_base}_diarization.vtt")
        files.download("speaker_timeline.png")
        files.download("speaking_time_distribution.png")
    else:
        print("Diarization failed. Please check your access token and try again.")

if __name__ == "__main__":
    main()

!pip install transformers sentencepiece nltk rouge-score
!pip install torch torchvision torchaudio

import torch
from transformers import (
    PegasusForConditionalGeneration,
    PegasusTokenizer,
    T5ForConditionalGeneration,
    T5Tokenizer,
    BartForConditionalGeneration,
    BartTokenizer
)
from google.colab import files
import nltk
from nltk.tokenize import sent_tokenize
import numpy as np
from rouge_score import rouge_scorer
import json
import pandas as pd
from typing import List, Dict, Any
import time

class AdvancedSummarizer:
    def __init__(self):
        """Initialize summarization models and tokenizers"""
        # Download required NLTK data
        nltk.download('punkt')

        # Initialize device
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")

        # Initialize models and tokenizers
        print("Loading models... This may take a few minutes.")

        # Pegasus model (good for abstractive summarization)
        self.pegasus_model = PegasusForConditionalGeneration.from_pretrained(
            'google/pegasus-large').to(self.device)
        self.pegasus_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')

        # BART model (good for both abstractive and extractive elements)
        self.bart_model = BartForConditionalGeneration.from_pretrained(
            'facebook/bart-large-cnn').to(self.device)
        self.bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')

        # T5 model (good for structured summarization)
        self.t5_model = T5ForConditionalGeneration.from_pretrained(
            't5-base').to(self.device)
        self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')

        # Initialize ROUGE scorer
        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'],
                                             use_stemmer=True)

    def preprocess_text(self, text: str) -> List[str]:
        """
        Preprocess text by splitting into chunks suitable for model input
        """
        # Split text into sentences
        sentences = sent_tokenize(text)

        # Initialize chunks
        chunks = []
        current_chunk = ""

        # Create chunks of appropriate size
        for sentence in sentences:
            if len(current_chunk) + len(sentence) < 1024:
                current_chunk += sentence + " "
            else:
                chunks.append(current_chunk.strip())
                current_chunk = sentence + " "

        # Add the last chunk if it exists
        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks

    def generate_pegasus_summary(self, text: str, max_length: int = 150) -> str:
        """Generate summary using Pegasus model"""
        inputs = self.pegasus_tokenizer(text,
                                      max_length=1024,
                                      truncation=True,
                                      return_tensors="pt").to(self.device)

        summary_ids = self.pegasus_model.generate(
            inputs["input_ids"],
            max_length=max_length,
            min_length=30,
            num_beams=4,
            length_penalty=2.0,
            no_repeat_ngram_size=3
        )

        return self.pegasus_tokenizer.decode(summary_ids[0],
                                           skip_special_tokens=True)

    def generate_bart_summary(self, text: str, max_length: int = 150) -> str:
        """Generate summary using BART model"""
        inputs = self.bart_tokenizer(text,
                                   max_length=1024,
                                   truncation=True,
                                   return_tensors="pt").to(self.device)

        summary_ids = self.bart_model.generate(
            inputs["input_ids"],
            max_length=max_length,
            min_length=30,
            num_beams=4,
            length_penalty=2.0,
            no_repeat_ngram_size=3
        )

        return self.bart_tokenizer.decode(summary_ids[0],
                                        skip_special_tokens=True)

    def generate_t5_summary(self, text: str, max_length: int = 150) -> str:
        """Generate summary using T5 model"""
        inputs = self.t5_tokenizer(f"summarize: {text}",
                                 max_length=1024,
                                 truncation=True,
                                 return_tensors="pt").to(self.device)

        summary_ids = self.t5_model.generate(
            inputs["input_ids"],
            max_length=max_length,
            min_length=30,
            num_beams=4,
            length_penalty=2.0,
            no_repeat_ngram_size=3
        )

        return self.t5_tokenizer.decode(summary_ids[0],
                                      skip_special_tokens=True)

    def evaluate_summaries(self,
                         original_text: str,
                         summaries: Dict[str, str]) -> Dict[str, Dict]:
        """
        Evaluate summaries using ROUGE metrics
        """
        evaluations = {}

        for model_name, summary in summaries.items():
            scores = self.scorer.score(original_text, summary)
            evaluations[model_name] = {
                'rouge1': scores['rouge1'].fmeasure,
                'rouge2': scores['rouge2'].fmeasure,
                'rougeL': scores['rougeL'].fmeasure
            }

        return evaluations

    def generate_comprehensive_summary(self,
                                    text: str,
                                    max_length: int = 150) -> Dict[str, Any]:
        """
        Generate comprehensive summary using multiple models
        """
        # Process text in chunks if necessary
        chunks = self.preprocess_text(text)

        # Generate summaries for each chunk using different models
        chunk_summaries = []
        for chunk in chunks:
            summaries = {
                'pegasus': self.generate_pegasus_summary(chunk, max_length),
                'bart': self.generate_bart_summary(chunk, max_length),
                't5': self.generate_t5_summary(chunk, max_length)
            }
            chunk_summaries.append(summaries)

        # Combine chunk summaries
        combined_summaries = {
            'pegasus': ' '.join([s['pegasus'] for s in chunk_summaries]),
            'bart': ' '.join([s['bart'] for s in chunk_summaries]),
            't5': ' '.join([s['t5'] for s in chunk_summaries])
        }

        # Evaluate summaries
        evaluations = self.evaluate_summaries(text, combined_summaries)

        # Select best summary based on ROUGE scores
        best_model = max(evaluations.items(),
                        key=lambda x: x[1]['rougeL'])[0]

        return {
            'summaries': combined_summaries,
            'evaluations': evaluations,
            'best_summary': combined_summaries[best_model],
            'best_model': best_model
        }

def save_results(results: Dict[str, Any], filename: str):
    """Save summarization results to files"""
    # Save detailed JSON report
    with open(f"{filename}_summary_report.json", 'w') as f:
        json.dump(results, f, indent=4)

    # Save summaries in markdown format
    with open(f"{filename}_summaries.md", 'w') as f:
        f.write("# Text Summarization Report\n\n")

        f.write("## Best Summary\n")
        f.write(f"Generated by {results['best_model']} model:\n")
        f.write(results['best_summary'])
        f.write("\n\n")

        f.write("## All Model Summaries\n")
        for model, summary in results['summaries'].items():
            f.write(f"### {model.upper()} Model\n")
            f.write(summary)
            f.write("\n\n")

        f.write("## Evaluation Metrics\n")
        f.write("| Model | ROUGE-1 | ROUGE-2 | ROUGE-L |\n")
        f.write("|-------|---------|---------|----------|\n")
        for model, scores in results['evaluations'].items():
            f.write(f"| {model} | {scores['rouge1']:.3f} | {scores['rouge2']:.3f} | {scores['rougeL']:.3f} |\n")

def main():
    print("Please upload your text file...")
    uploaded = files.upload()

    # Read the text file
    filename = list(uploaded.keys())[0]
    with open(filename, 'r', encoding='utf-8') as f:
        text = f.read()

    # Initialize summarizer
    print("\nInitializing summarizer...")
    summarizer = AdvancedSummarizer()

    # Generate summaries
    print("\nGenerating summaries... This may take a few minutes.")
    start_time = time.time()
    results = summarizer.generate_comprehensive_summary(text)
    processing_time = time.time() - start_time

    # Add processing time to results
    results['processing_time'] = processing_time

    # Save results
    output_base = filename.split('.')[0]
    save_results(results, output_base)

    # Print summary
    print(f"\nSummarization completed in {processing_time:.2f} seconds")
    print(f"Best performing model: {results['best_model']}")
    print("\nBest Summary:")
    print(results['best_summary'])

    # Download results
    files.download(f"{output_base}_summary_report.json")
    files.download(f"{output_base}_summaries.md")

if __name__ == "__main__":
    main()

!pip install transformers pandas numpy torch
!pip install rouge-score
!pip install nltk

import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
from transformers import pipeline
import pandas as pd
import numpy as np
import json
from google.colab import files
import nltk
from nltk.tokenize import sent_tokenize
import re
from datetime import datetime

class ActionPlanGenerator:
    def __init__(self):
        """Initialize the models and tokenizers"""
        # Initialize T5 model for text generation
        self.model_name = "t5-base"
        self.tokenizer = T5Tokenizer.from_pretrained(self.model_name)
        self.model = T5ForConditionalGeneration.from_pretrained(self.model_name)

        # Initialize summarization pipeline
        self.summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

        # Move model to GPU if available
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)

        # Download required NLTK data
        nltk.download('punkt')

    def load_and_process_data(self, transcription_file, sentiment_file, diarization_file):
        """Load and process all input files"""
        # Load transcription
        with open(transcription_file, 'r', encoding='utf-8') as f:
            transcription = f.read()

        # Load sentiment analysis
        with open(sentiment_file, 'r', encoding='utf-8') as f:
            sentiment_data = json.load(f)

        # Load diarization
        diarization_df = pd.read_csv(diarization_file)

        return transcription, sentiment_data, diarization_df

    def extract_key_points(self, text):
        """Extract key points from the text"""
        # Split into sentences
        sentences = sent_tokenize(text)

        # Generate summary points
        chunks = self.chunk_text(text, max_length=1024)
        key_points = []

        for chunk in chunks:
            summary = self.summarizer(chunk, max_length=100, min_length=30, do_sample=False)
            key_points.extend(sent_tokenize(summary[0]['summary_text']))

        return key_points

    def analyze_sentiment_trends(self, sentiment_data):
        """Analyze sentiment trends from the sentiment analysis data"""
        # Extract overall sentiment
        overall_sentiment = sentiment_data.get('overall_sentiment', {})

        # Extract emotional analysis
        emotions = sentiment_data.get('emotional_analysis', [])

        # Summarize the overall sentiment
        if overall_sentiment:
            vader_scores = overall_sentiment.get('vader', {})
            if vader_scores:
                if vader_scores['compound'] >= 0.05:
                    return "Positive"
                elif vader_scores['compound'] <= -0.05:
                    return "Negative"
                else:
                    return "Neutral"

        return "Unknown"

    def analyze_speaker_dynamics(self, diarization_df):
        """Analyze speaker interaction patterns"""
        # Calculate speaking time per speaker
        speaker_times = diarization_df.groupby('speaker')['duration'].agg(['sum', 'count'])

        # Calculate turn-taking patterns
        speaker_turns = []
        prev_speaker = None

        for speaker in diarization_df['speaker']:
            if prev_speaker and prev_speaker != speaker:
                speaker_turns.append((prev_speaker, speaker))
            prev_speaker = speaker

        return speaker_times, speaker_turns

    def generate_action_items(self, key_points, sentiment_data, speaker_analysis):
        """Generate specific action items based on the analysis"""
        # Prepare prompt for T5
        prompt = self.prepare_action_prompt(key_points, sentiment_data, speaker_analysis)

        # Generate action items using T5
        inputs = self.tokenizer.encode("generate action items: " + prompt,
                                     return_tensors="pt",
                                     max_length=512,
                                     truncation=True).to(self.device)

        outputs = self.model.generate(
            inputs,
            max_length=150,
            min_length=50,
            num_return_sequences=3,
            do_sample=True,
            temperature=0.7,
            top_k=50,
            top_p=0.9
        )

        action_items = []
        for output in outputs:
            decoded = self.tokenizer.decode(output, skip_special_tokens=True)
            action_items.extend(self.parse_action_items(decoded))

        return action_items

    def prepare_action_prompt(self, key_points, sentiment_data, speaker_analysis):
        """Prepare a prompt for action item generation"""
        prompt = "Based on the following information:\n"

        # Add key points
        prompt += "\nKey Points:\n"
        for idx, point in enumerate(key_points, 1):
            prompt += f"{idx}. {point}\n"

        # Add sentiment summary
        prompt += "\nSentiment Overview:\n"
        prompt += f"- Overall mood: {self.analyze_sentiment_trends(sentiment_data)}\n"

        # Add speaker dynamics
        prompt += "\nParticipant Dynamics:\n"
        prompt += self.summarize_speaker_dynamics(speaker_analysis)

        prompt += "\nCreate specific, actionable items that address the key points and concerns raised."

        return prompt

    @staticmethod
    def chunk_text(text, max_length=1024):
        """Split text into chunks of maximum length"""
        words = text.split()
        chunks = []
        current_chunk = []
        current_length = 0

        for word in words:
            if current_length + len(word) + 1 <= max_length:
                current_chunk.append(word)
                current_length += len(word) + 1
            else:
                chunks.append(' '.join(current_chunk))
                current_chunk = [word]
                current_length = len(word) + 1

        if current_chunk:
            chunks.append(' '.join(current_chunk))

        return chunks

    @staticmethod
    def summarize_speaker_dynamics(speaker_analysis):
        """Summarize the speaker dynamics"""
        speaker_times, speaker_turns = speaker_analysis

        summary = ""
        summary += f"The participants had a total of {len(speaker_turns)} speaker turns.\n"
        summary += "The speaking time breakdown is:\n"

        for speaker, stats in speaker_times.iterrows():
            summary += f"- {speaker}: {stats['sum']:.2f} seconds ({stats['count']} turns, {stats['sum']/stats['count']:.2f} seconds per turn)\n"

        return summary

    @staticmethod
    def parse_action_items(text):
        """Parse generated text into distinct action items"""
        # Split on common action item markers
        markers = ['\n-', '\nâ€¢', '\n1.', '\n2.', '\n3.', '\n4.', '\n5.']
        items = []

        for marker in markers:
            if marker in text:
                split_items = text.split(marker)
                items.extend([item.strip() for item in split_items if item.strip()])

        return items if items else [text]

    def generate_report(self, key_points, action_items, sentiment_data, speaker_analysis):
        """Generate a comprehensive action plan report"""
        report = {
            'summary': {
                'key_points': key_points,
                'sentiment': self.analyze_sentiment_trends(sentiment_data),
                'speaker_dynamics': self.summarize_speaker_dynamics(speaker_analysis)
            },
            'action_items': action_items,
            'priority_levels': self.assign_priorities(action_items, sentiment_data),
            'timeline': self.suggest_timeline(action_items),
            'responsible_parties': self.suggest_responsible_parties(action_items, speaker_analysis)
        }

        return report

    def format_report(self, report):
        """Format the report in a readable structure"""
        formatted = f"""
Action Plan Report
=================
Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Executive Summary
----------------
{self.format_key_points(report['summary']['key_points'])}

Overall Sentiment
----------------
{report['summary']['sentiment']}

Participant Dynamics
------------------
{report['summary']['speaker_dynamics']}

Action Items
-----------
{self.format_action_items(report['action_items'], report['priority_levels'],
                         report['timeline'], report['responsible_parties'])}

Next Steps
---------
1. Review and validate action items with stakeholders
2. Assign responsibilities and deadlines
3. Schedule follow-up meeting to track progress
4. Update plan based on feedback

Notes
-----
- Priority levels are suggestions based on sentiment analysis and context
- Timeline suggestions are based on action complexity
- Responsible party assignments are based on speaker participation and context
"""
        return formatted

    @staticmethod
    def format_key_points(points):
        """Format key points for the report"""
        return "\n".join(f"- {point}" for point in points)

    @staticmethod
    def format_action_items(items, priorities, timeline, responsible):
        """Format action items with their metadata"""
        formatted = ""
        for idx, item in enumerate(items):
            formatted += f"\n{idx+1}. {item}\n"
            formatted += f"   Priority: {priorities[idx]}\n"
            formatted += f"   Timeline: {timeline[idx]}\n"
            formatted += f"   Responsible: {responsible[idx]}\n"
        return formatted

    @staticmethod
    def assign_priorities(action_items, sentiment_data):
        """Assign priority levels to action items"""
        # Simple priority assignment based on keyword matching
        high_priority_keywords = ['urgent', 'immediate', 'critical', 'important']
        low_priority_keywords = ['later', 'eventually', 'consider', 'might']

        priorities = []
        for item in action_items:
            if any(keyword in item.lower() for keyword in high_priority_keywords):
                priorities.append("High")
            elif any(keyword in item.lower() for keyword in low_priority_keywords):
                priorities.append("Low")
            else:
                priorities.append("Medium")

        return priorities

    @staticmethod
    def suggest_timeline(action_items):
        """Suggest implementation timeline for action items"""
        # Simple timeline suggestion based on action item length and complexity
        timelines = []
        for item in action_items:
            words = len(item.split())
            if words < 10:
                timelines.append("Immediate (1-2 days)")
            elif words < 20:
                timelines.append("Short-term (1-2 weeks)")
            else:
                timelines.append("Medium-term (2-4 weeks)")

        return timelines

    @staticmethod
    def suggest_responsible_parties(action_items, speaker_analysis):
        """Suggest responsible parties based on speaker analysis"""
        speaker_times, _ = speaker_analysis
        speakers = speaker_times.index.tolist()
        return [np.random.choice(speakers) for _ in action_items]

def main():
    print("Please upload your transcription file...")
    uploaded_transcription = files.upload()
    transcription_file = list(uploaded_transcription.keys())[0]

    print("\nPlease upload your sentiment analysis file...")
    uploaded_sentiment = files.upload()
    sentiment_file = list(uploaded_sentiment.keys())[0]

    print("\nPlease upload your diarization file...")
    uploaded_diarization = files.upload()
    diarization_file = list(uploaded_diarization.keys())[0]

    # Initialize generator
    generator = ActionPlanGenerator()

    # Load and process data
    transcription, sentiment_data, diarization_df = generator.load_and_process_data(
        transcription_file, sentiment_file, diarization_file
    )

    # Extract key points
    key_points = generator.extract_key_points(transcription)

    # Analyze speaker dynamics
    speaker_analysis = generator.analyze_speaker_dynamics(diarization_df)

    # Generate action items
    action_items = generator.generate_action_items(key_points, sentiment_data, speaker_analysis)

    # Generate comprehensive report
    report = generator.generate_report(key_points, action_items, sentiment_data, speaker_analysis)

    # Format report
    formatted_report = generator.format_report(report)

    # Save report
    report_filename = "action_plan_report.txt"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(formatted_report)

    # Download report
    files.download(report_filename)

    print("\nAction plan has been generated and downloaded!")

if __name__ == "__main__":
    main()

import os
import json
import smtplib
import pandas as pd
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files

class AnalysisEmailer:
    def __init__(self, sender_email, sender_password):
        self.sender_email = sender_email
        self.sender_password = sender_password
        self.smtp_server = "smtp.gmail.com"
        self.smtp_port = 587

    def format_time(self, seconds):
        """Convert seconds to readable time format"""
        minutes, seconds = divmod(seconds, 60)
        hours, minutes = divmod(minutes, 60)
        return f"{int(hours)}h {int(minutes)}m {int(seconds)}s"

    def create_speaker_chart(self, diarization_data):
        """Create speaker participation chart"""
        speaker_times = {}
        for segment in diarization_data:
            speaker = segment['speaker']
            duration = segment['end'] - segment['start']
            speaker_times[speaker] = speaker_times.get(speaker, 0) + duration

        plt.figure(figsize=(8, 6))
        plt.pie(speaker_times.values(), labels=speaker_times.keys(), autopct='%1.1f%%')
        plt.title('Speaker Participation Distribution')
        plt.savefig('speaker_distribution.png')
        plt.close()

    def generate_email_content(self, transcription, sentiment_analysis, diarization_data):
        """Generate HTML email content with analysis results"""

        # Process speaker data
        speaker_times = {}
        for segment in diarization_data:
            speaker = segment['speaker']
            duration = segment['end'] - segment['start']
            speaker_times[speaker] = speaker_times.get(speaker, 0) + duration

        # Create speaker chart
        self.create_speaker_chart(diarization_data)

        # Extract key sentiment metrics
        sentiment_scores = {
            'positive': sentiment_analysis.get('overall_sentiment', {}).get('vader', {}).get('pos', 0),
            'negative': sentiment_analysis.get('overall_sentiment', {}).get('vader', {}).get('neg', 0),
            'neutral': sentiment_analysis.get('overall_sentiment', {}).get('vader', {}).get('neu', 0),
        }

        # Generate action items based on analysis
        action_items = self.generate_action_items(sentiment_scores, speaker_times)

        # Create HTML email template
        html_content = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; }}
                .container {{ max-width: 800px; margin: 0 auto; padding: 20px; }}
                .section {{ margin-bottom: 30px; background-color: #f8f9fa; padding: 20px; border-radius: 5px; }}
                .highlight {{ color: #2c3e50; font-weight: bold; }}
                .action-item {{ background-color: #e9ecef; padding: 10px; margin: 5px 0; border-radius: 3px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Meeting Analysis Summary</h1>
                <p>Generated on: {datetime.now().strftime("%Y-%m-%d %H:%M")}</p>

                <div class="section">
                    <h2>Executive Summary</h2>
                    <p>Meeting Duration: {self.format_time(sum(speaker_times.values()))}</p>
                    <p>Number of Participants: {len(speaker_times)}</p>
                    <p>Overall Sentiment: {self.get_overall_sentiment(sentiment_scores)}</p>
                </div>

                <div class="section">
                    <h2>Participation Analysis</h2>
                    <h3>Speaking Time Distribution:</h3>
                    <ul>
                    {self.format_speaker_distribution(speaker_times)}
                    </ul>
                </div>

                <div class="section">
                    <h2>Sentiment Analysis</h2>
                    <p>Sentiment Breakdown:</p>
                    <ul>
                        <li>Positive: {sentiment_scores['positive']:.1%}</li>
                        <li>Neutral: {sentiment_scores['neutral']:.1%}</li>
                        <li>Negative: {sentiment_scores['negative']:.1%}</li>
                    </ul>
                    {self.format_sentiment_insights(sentiment_analysis)}
                </div>

                <div class="section">
                    <h2>Key Discussion Points</h2>
                    {self.extract_key_points(transcription)}
                </div>

                <div class="section">
                    <h2>Action Items</h2>
                    {action_items}
                </div>

                <div class="section">
                    <h2>Next Steps</h2>
                    <ul>
                        <li>Review and approve meeting minutes</li>
                        <li>Distribute action items to respective owners</li>
                        <li>Schedule follow-up meetings as needed</li>
                        <li>Track progress on action items</li>
                    </ul>
                </div>
            </div>
        </body>
        </html>
        """
        return html_content

    def format_speaker_distribution(self, speaker_times):
        """Format speaker distribution as HTML list"""
        total_time = sum(speaker_times.values())
        html_list = ""
        for speaker, duration in speaker_times.items():
            percentage = (duration / total_time) * 100
            html_list += f"<li>{speaker}: {self.format_time(duration)} ({percentage:.1f}%)</li>"
        return html_list

    def get_overall_sentiment(self, sentiment_scores):
        """Determine overall sentiment"""
        if sentiment_scores['positive'] > sentiment_scores['negative']:
            return "Primarily Positive"
        elif sentiment_scores['negative'] > sentiment_scores['positive']:
            return "Primarily Negative"
        else:
            return "Neutral"

    def format_sentiment_insights(self, sentiment_analysis):
        """Format sentiment insights"""
        emotions = sentiment_analysis.get('emotional_analysis', [])
        if not emotions:
            return ""

        html = "<h3>Emotional Insights:</h3><ul>"
        for emotion in emotions:
            html += f"<li>{emotion['label'].capitalize()}: {emotion['score']:.1%}</li>"
        html += "</ul>"
        return html

    def extract_key_points(self, transcription):
        """Extract key discussion points from transcription"""
        # Simple extraction of sentences containing key phrases
        key_phrases = ["important", "priority", "need to", "must", "should", "agree", "decision"]
        sentences = transcription.split('.')
        key_points = []

        for sentence in sentences:
            if any(phrase in sentence.lower() for phrase in key_phrases):
                key_points.append(sentence.strip())

        if not key_points:
            return "<p>No specific key points identified.</p>"

        html = "<ul>"
        for point in key_points[:5]:  # Limit to top 5 points
            html += f"<li>{point}.</li>"
        html += "</ul>"
        return html

    def generate_action_items(self, sentiment_scores, speaker_times):
        """Generate action items based on analysis"""
        action_items = "<ul>"

        # Add items based on sentiment
        if sentiment_scores['negative'] > 0.3:
            action_items += "<li class='action-item'>Schedule follow-up discussions for topics that received negative feedback</li>"

        # Add items based on participation
        total_time = sum(speaker_times.values())
        for speaker, duration in speaker_times.items():
            if (duration / total_time) < 0.1:
                action_items += f"<li class='action-item'>Encourage more participation from {speaker} in future meetings</li>"

        # Add general action items
        action_items += """
            <li class='action-item'>Circulate meeting minutes for review</li>
            <li class='action-item'>Schedule follow-up meetings for key decisions</li>
            <li class='action-item'>Create timeline for implementing discussed changes</li>
            <li class='action-item'>Assign owners to action items</li>
        </ul>"""

        return action_items

    def send_email(self, recipient_email, subject, html_content, files_to_attach=None):
        """Send email with attachments"""
        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = self.sender_email
        msg['To'] = recipient_email

        # Attach HTML content
        msg.attach(MIMEText(html_content, 'html'))

        # Attach files
        if files_to_attach:
            for file_path in files_to_attach:
                try:
                    with open(file_path, 'rb') as f:
                        part = MIMEApplication(f.read(), _subtype="txt")
                        part.add_header('Content-Disposition', 'attachment',
                                      filename=os.path.basename(file_path))
                        msg.attach(part)
                except Exception as e:
                    print(f"Error attaching file {file_path}: {str(e)}")

        # Send email
        try:
            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
                server.starttls()
                server.login(self.sender_email, self.sender_password)
                server.send_message(msg)
            return True
        except Exception as e:
            print(f"Error sending email: {str(e)}")
            return False

def main():
    # Get email credentials
    print("Enter your Gmail address:")
    sender_email = input()
    print("Enter your Gmail app password:")
    sender_password = input()
    print("Enter recipient email address:")
    recipient_email = input()

    # Load analysis files
    print("\nLoading analysis files...")
    with open('transcription.txt', 'r', encoding='utf-8') as f:
        transcription = f.read()

    with open('sentiment_analysis.json', 'r') as f:
        sentiment_analysis = json.load(f)

    with open('diarization.json', 'r') as f:
        diarization_data = json.load(f)

    # Initialize emailer
    emailer = AnalysisEmailer(sender_email, sender_password)

    # Generate email content
    print("Generating email content...")
    html_content = emailer.generate_email_content(
        transcription,
        sentiment_analysis,
        diarization_data
    )

    # Files to attach
    attachments = [
        'transcription.txt',
        'sentiment_analysis.json',
        'diarization.json',
        'speaker_distribution.png'
    ]

    # Send email
    print("Sending email...")
    success = emailer.send_email(
        recipient_email,
        "Meeting Analysis Summary and Action Items",
        html_content,
        attachments
    )

    if success:
        print("Email sent successfully!")
    else:
        print("Failed to send email. Please check the error messages above.")

if __name__ == "__main__":
    main()